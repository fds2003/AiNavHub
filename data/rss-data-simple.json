{
  "articles": [
    {
      "title": "Advance Trustworthy AI and ML, and Identify Best Practices for Scaling AI",
      "title_zh": "Advance Trustworthy AI and ML, and Identify Best Practices for Scaling AI",
      "description": "By John P. Desmond, AI Trends Editor   Advancing trustworthy AI and machine learning to mitigate agency risk is a priority for the US Department of Energy (DOE), and identifying best practices for implementing AI at scale is a priority for the US General Services Administration (GSA).   That’s what attendees learned in two sessions at the AI [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/advance-trustworthy-ai-and-ml-and-identify-best-practices-for-scaling-ai/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Best Practices for Building the AI Development Platform in Government",
      "title_zh": "Best Practices for Building the AI Development Platform in Government",
      "description": "By John P. Desmond, AI Trends Editor  The AI stack defined by Carnegie Mellon University is fundamental to the approach being taken by the US Army for its AI development platform efforts, according to Isaac Faber, Chief Data Scientist at the US Army AI Integration Center, speaking at the AI World Government event held in-person and virtually [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/best-practices-for-building-the-ai-development-platform-in-government/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "How Accountability Practices Are Pursued by AI Engineers in the Federal Government",
      "title_zh": "How Accountability Practices Are Pursued by AI Engineers in the Federal Government",
      "description": "By John P. Desmond, AI Trends Editor    Two experiences of how AI developers within the federal government are pursuing AI accountability practices were outlined at the AI World Government event held virtually and in-person this week in Alexandria, Va.  Taka Ariga, chief data scientist and director at the US Government Accountability Office, described an AI accountability framework he uses within his agency [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/how-accountability-practices-are-pursued-by-ai-engineers-in-the-federal-government/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents",
      "title_zh": "SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents",
      "description": "arXiv:2510.12985v1 Announce Type: new \nAbstract: We present Sentinel, the first framework for formally evaluating the physical safety of Large Language Model(LLM-based) embodied agents across the semantic, plan, and trajectory levels. Unlike prior methods that rely on heuristic rules or subjective LLM judgments, Sentinel grounds practical safety requirements in formal temporal logic (TL) semantics that can precisely specify state invariants, temporal dependencies, and timing constraints. It then",
      "link": "https://arxiv.org/abs/2510.12985",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-16"
    },
    {
      "title": "Getting Government AI Engineers to Tune into AI Ethics Seen as Challenge",
      "title_zh": "Getting Government AI Engineers to Tune into AI Ethics Seen as Challenge",
      "description": "By John P. Desmond, AI Trends Editor   Engineers tend to see things in unambiguous terms, which some may call Black and White terms, such as a choice between right or wrong and good and bad. The consideration of ethics in AI is highly nuanced, with vast gray areas, making it  challenging for AI software engineers to [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/getting-government-ai-engineers-to-tune-into-ai-ethics-seen-as-challenge/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "Novelty In The Game Of Go Provides Bright Insights For AI And Autonomous Vehicles",
      "title_zh": "Novelty In The Game Of Go Provides Bright Insights For AI And Autonomous Vehicles",
      "description": "By Lance Eliot, the AI Trends Insider   We already expect that humans to exhibit flashes of brilliance. It might not happen all the time, but the act itself is welcomed and not altogether disturbing when it occurs.    What about when Artificial Intelligence (AI) seems to display an act of novelty? Any such instance is bound to get our attention; [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-insider/novelty-in-the-game-of-go-provides-bright-insights-for-ai-and-autonomous-vehicles/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Promise and Perils of Using AI for Hiring: Guard Against Data Bias",
      "title_zh": "Promise and Perils of Using AI for Hiring: Guard Against Data Bias",
      "description": "By AI Trends Staff   While AI in hiring is now widely used for writing job descriptions, screening candidates, and automating interviews, it poses a risk of wide discrimination if not implemented carefully.  That was the message from Keith Sonderling, Commissioner with the US Equal Opportunity Commision, speaking at the AI World Government event held live and virtually in [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/promise-and-perils-of-using-ai-for-hiring-guard-against-data-bias/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Predictive Maintenance Proving Out as Successful AI Use Case",
      "title_zh": "Predictive Maintenance Proving Out as Successful AI Use Case",
      "description": "By John P. Desmond, AI Trends Editor   More companies are successfully exploiting predictive maintenance systems that combine AI and IoT sensors to collect data that anticipates breakdowns and recommends preventive action before break or machines fail, in a demonstration of an AI use case with proven value.   This growth is reflected in optimistic market forecasts. [&#8230;]]]>",
      "link": "https://www.aitrends.com/predictive-analytics/predictive-maintenance-proving-out-as-successful-ai-use-case/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Digital Natives Seen Having Advantages as Part of Government AI Engineering Teams",
      "title_zh": "Digital Natives Seen Having Advantages as Part of Government AI Engineering Teams",
      "description": "By John P. Desmond, AI Trends Editor   AI is more accessible to young people in the workforce who grew up as ‘digital natives’ with Alexa and self-driving cars as part of the landscape, giving them expectations grounded in their experience of what is possible.   That idea set the foundation for a panel discussion at AI World [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/digital-natives-seen-having-advantages-as-part-of-government-ai-engineering-teams/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation",
      "title_zh": "Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation",
      "description": "arXiv:2510.13195v1 Announce Type: new \nAbstract: The advent of large language models (LLMs) has enabled agents to represent virtual humans in societal simulations, facilitating diverse interactions within complex social systems. However, existing LLM-based agents exhibit severe limitations in affective cognition: They fail to simulate the bounded rationality essential for bridging virtual and real-world services; They lack empirically validated integration mechanisms embedding emotions within ag",
      "link": "https://arxiv.org/abs/2510.13195",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-16"
    },
    {
      "title": "Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning",
      "title_zh": "Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning",
      "description": "arXiv:2510.13214v1 Announce Type: new \nAbstract: Recent advances in Large Language Models (LLMs) demonstrate that chain-of-thought prompting and deep reasoning substantially enhance performance on complex tasks, and multi-agent systems can further improve accuracy by enabling model debates. However, applying deep reasoning to all problems is computationally expensive. To mitigate these costs, we propose a complementary agent system integrating small and large LLMs. The small LLM first generates ",
      "link": "https://arxiv.org/abs/2510.13214",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-16"
    },
    {
      "title": "From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model",
      "title_zh": "From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model",
      "description": "arXiv:2510.13002v1 Announce Type: new \nAbstract: Vehicle crashes involve complex interactions between road users, split-second decisions, and challenging environmental conditions. Among these, two-vehicle crashes are the most prevalent, accounting for approximately 70% of roadway crashes and posing a significant challenge to traffic safety. Identifying Driver Hazardous Action (DHA) is essential for understanding crash causation, yet the reliability of DHA data in large-scale databases is limited",
      "link": "https://arxiv.org/abs/2510.13002",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-16"
    },
    {
      "title": "From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models",
      "title_zh": "From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models",
      "description": "arXiv:2510.12864v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly being deployed as the reasoning engines for agentic AI systems, yet they exhibit a critical flaw: a rigid adherence to explicit rules that leads to decisions misaligned with human common sense and intent. This \"rule-rigidity\" is a significant barrier to building trustworthy autonomous agents. While prior work has shown that supervised fine-tuning (SFT) with human explanations can mitigate this issue, S",
      "link": "https://arxiv.org/abs/2510.12864",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-16"
    },
    {
      "title": "EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems",
      "title_zh": "EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems",
      "description": "arXiv:2510.13220v1 Announce Type: new \nAbstract: A fundamental limitation of current AI agents is their inability to learn complex skills on the fly at test time, often behaving like \"clever but clueless interns\" in novel environments. This severely limits their practical utility. To systematically measure and drive progress on this challenge, we first introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a new evaluation setup where an agent must play the same game for several co",
      "link": "https://arxiv.org/abs/2510.13220",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-16"
    },
    {
      "title": "Toward Reasoning-Centric Time-Series Analysis",
      "title_zh": "Toward Reasoning-Centric Time-Series Analysis",
      "description": "arXiv:2510.13029v1 Announce Type: new \nAbstract: Traditional time series analysis has long relied on pattern recognition, trained on static and well-established benchmarks. However, in real-world settings -- where policies shift, human behavior adapts, and unexpected events unfold -- effective analysis must go beyond surface-level trends to uncover the actual forces driving them. The recent rise of Large Language Models (LLMs) presents new opportunities for rethinking time series analysis by int",
      "link": "https://arxiv.org/abs/2510.13029",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-16"
    },
    {
      "title": "Personalized Learning Path Planning with Goal-Driven Learner State Modeling",
      "title_zh": "Personalized Learning Path Planning with Goal-Driven Learner State Modeling",
      "description": "arXiv:2510.13215v1 Announce Type: new \nAbstract: Personalized Learning Path Planning (PLPP) aims to design adaptive learning paths that align with individual goals. While large language models (LLMs) show potential in personalizing learning experiences, existing approaches often lack mechanisms for goal-aligned planning. We introduce Pxplore, a novel framework for PLPP that integrates a reinforcement-based training paradigm and an LLM-driven educational architecture. We design a structured learn",
      "link": "https://arxiv.org/abs/2510.13215",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-16"
    }
  ]
}